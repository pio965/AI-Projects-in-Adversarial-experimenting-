# -*- coding: utf-8 -*-
"""Adversarial Experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vbTVdIXOmGy4Bw8lQ7GsHRZTzCaMKHIM
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
!pip install opencv-python open3d numpy matplotlib tqdm
!pip install pykitti
!git clone https://github.com/ultralytics/yolov5  # For YOLOv5 pretrained models
# %cd yolov5
!pip install -r requirements.txt
# %cd ..

# Download minimal KITTI dataset (50 samples)
!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip
!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_velodyne.zip
!unzip data_object_image_2.zip -d ./kitti_data
!unzip data_object_velodyne.zip -d ./kitti_data

pip install open3d

import numpy as np
import open3d as o3d
import glob

def load_lidar_data(file_path):
    scan = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)  # (x, y, z, intensity)
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(scan[:, :3])  # Extract x, y, z
    return pcd

# Get first 5 LiDAR samples
lidar_files = sorted(glob.glob("./kitti_data/training/velodyne/*.bin"))

for file in lidar_files[:5]:
    print(f"Visualizing: {file}")
    pcd = load_lidar_data(file)
    o3d.visualization.draw_geometries([pcd], window_name="KITTI LiDAR Visualization")

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

import torch
import torchvision.models as models

# Initialize model without pretrained weights
model = models.resnet18(weights=None)

# Manually download and load weights
torch.hub.download_url_to_file(
    'https://download.pytorch.org/models/resnet18-f37072fd.pth',
    'resnet18.pth'
)

# Load weights
model.load_state_dict(torch.load('resnet18.pth', map_location=torch.device('cpu')))
model.eval()

import torch
import torch.nn.functional as F
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt


# Load KITTI image
img_path = "./kitti_data/training/image_2/000000.png"  # Change if needed
img = Image.open(img_path).convert('RGB')
plt.imshow(img)
plt.title("Original Image")
plt.show()

# FGSM Attack Function
def fgsm_attack(model, image, label, epsilon=0.03):
    image_tensor = torch.tensor(np.array(image)/255.0, dtype=torch.float32).permute(2,0,1).unsqueeze(0)
    image_tensor.requires_grad = True

    output = model(image_tensor)
    loss = F.cross_entropy(output, torch.tensor([label]))

    model.zero_grad()
    loss.backward()

    perturbed = image_tensor + epsilon * image_tensor.grad.sign()
    perturbed = torch.clamp(perturbed, 0, 1)
    return perturbed.squeeze().permute(1,2,0).detach().numpy()

# Load Pretrained Model
model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)
model.eval()

# Generate and Display Adversarial Example
adv_img = fgsm_attack(model, img, label=9)  # Class 9 (traffic light)
plt.imshow(adv_img)
plt.title("Adversarial Image (Îµ=0.03)")
plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from PIL import Image
import glob

# Define CNN classifier
class AttackDetector(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16*53*53, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 2)  # Binary classification

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

# Initialize model, loss, and optimizer
model = AttackDetector()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

class KITTIDataset(Dataset):
    def __init__(self, image_folder, label):
        self.image_files = sorted(glob.glob(f"{image_folder}/*.png"))
        self.label = label  # 0 for clean, 1 for adversarial
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image = Image.open(self.image_files[idx]).convert("RGB")
        return self.transform(image), torch.tensor(self.label, dtype=torch.long)

# Load clean and adversarial datasets
clean_dataset = KITTIDataset("./kitti_data/training/image_2", label=0)
adv_dataset = KITTIDataset("./kitti_data/adv_images", label=1)

# Combine datasets
train_loader = DataLoader(clean_dataset + adv_dataset, batch_size=32, shuffle=True)

class KITTIDataset(Dataset):
    def __init__(self, image_folder, label):
        self.image_files = sorted(glob.glob(f"{image_folder}/*.png"))
        self.label = label  # 0 for clean, 1 for adversarial
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image = Image.open(self.image_files[idx]).convert("RGB")
        return self.transform(image), torch.tensor(self.label, dtype=torch.long)

# Load clean and adversarial datasets
clean_dataset = KITTIDataset("./kitti_data/training/image_2", label=0)
adv_dataset = KITTIDataset("./kitti_data/adv_images", label=1)

# Combine datasets
train_loader = DataLoader(clean_dataset + adv_dataset, batch_size=32, shuffle=True)

# Training Loop
num_epochs = 5
for epoch in range(num_epochs):
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')

# Load test dataset
test_loader = DataLoader(clean_dataset + adv_dataset, batch_size=32, shuffle=False)

# Compute accuracy
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Model Accuracy: {accuracy:.2f}%')

